{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to keep in mind when tackling this data:\n",
    "<br/>\n",
    "<ul>\n",
    "    <li><h5>Preprocessing:</h3></li>\n",
    "    <ul>\n",
    "        <li>Encode ingredient lists into features</li>\n",
    "        <li>Possibly one-hot encode each ingredient</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read json file\n",
    "train = pd.read_json(\"train.json\")\n",
    "y_train = train[\"cuisine\"]\n",
    "X_train = train[\"ingredients\"]\n",
    "\n",
    "# To build an encoding of ingredients (treating each phrase that represents an ingredient independently)\n",
    "word_index = {}\n",
    "ctr = 1\n",
    "encoded = np.zeros((len(X_train), 7000))\n",
    "for i in range(len(X_train)): # Loop through every example\n",
    "    for j in X_train.values[i]: # Loop through every ingredient\n",
    "        if j in word_index:\n",
    "            encoded[i, word_index[j]] = 1\n",
    "        else:\n",
    "            word_index[j] = ctr\n",
    "            encoded[i, ctr] = 1\n",
    "            ctr = ctr + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()\n",
    "y_train = pd.get_dummies(y_train)\n",
    "label = y_train.columns\n",
    "y_train = y_train.values\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 7000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(encoded, y_train)\n",
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(20, activation=\"softmax\"))\n",
    "\n",
    "adam = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam, loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29830 samples, validate on 9944 samples\n",
      "Epoch 1/10\n",
      "29830/29830 [==============================] - 26s 873us/step - loss: 1.6932 - acc: 0.5425 - val_loss: 1.0826 - val_acc: 0.6931\n",
      "Epoch 2/10\n",
      "29830/29830 [==============================] - 19s 652us/step - loss: 1.0700 - acc: 0.6970 - val_loss: 0.8837 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      "29830/29830 [==============================] - 19s 635us/step - loss: 0.8972 - acc: 0.7438 - val_loss: 0.8024 - val_acc: 0.7664\n",
      "Epoch 4/10\n",
      "29830/29830 [==============================] - 19s 624us/step - loss: 0.7987 - acc: 0.7685 - val_loss: 0.7664 - val_acc: 0.7723\n",
      "Epoch 5/10\n",
      "29830/29830 [==============================] - 19s 645us/step - loss: 0.7226 - acc: 0.7902 - val_loss: 0.7442 - val_acc: 0.7804\n",
      "Epoch 6/10\n",
      "29830/29830 [==============================] - 18s 613us/step - loss: 0.6616 - acc: 0.8075 - val_loss: 0.7345 - val_acc: 0.7825\n",
      "Epoch 7/10\n",
      "29830/29830 [==============================] - 18s 618us/step - loss: 0.6264 - acc: 0.8165 - val_loss: 0.7345 - val_acc: 0.7846\n",
      "Epoch 8/10\n",
      "29830/29830 [==============================] - 19s 627us/step - loss: 0.5852 - acc: 0.8257 - val_loss: 0.7376 - val_acc: 0.7861\n",
      "Epoch 9/10\n",
      "29830/29830 [==============================] - 20s 665us/step - loss: 0.5589 - acc: 0.8331 - val_loss: 0.7412 - val_acc: 0.7884\n",
      "Epoch 10/10\n",
      "29830/29830 [==============================] - 22s 752us/step - loss: 0.5238 - acc: 0.8428 - val_loss: 0.7478 - val_acc: 0.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b527080>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs = 10, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
